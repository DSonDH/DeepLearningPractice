# excercise with basic deep learning models and pytorch templates

├─0_dataloader  
├─1_template  
│  ├─config  
│  ├─model  
│  ├─train  
│  └─utils  
├─excercise  
└─MNIST_data  
    └─MNIST  

## mlp with numpy

## mlp with pytorch


## Tensorflow - Keras
딥러닝 모델 연산 최적화
@tf.fuction
@tf.fuction(git_compile=True)


## general modeling convention? tips
attention value의 variance가 높으므로 sqrt로 나누어준다.

residual block의 ensemble유사한 효과를 depth에 따라 크게 주는.  
즉 drop rate를 점차 커지게 한다.
https://paperswithcode.com/method/stochastic-depth

